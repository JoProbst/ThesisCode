{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "pd.set_option('display.max_colwidth', 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pyterrier as pt\n",
    "if not pt.started():\n",
    "    pt.init()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "docno_to_text = pd.read_csv('../CHS-2021/documents/Webdoc/crawl/txt_over_50.tsv', sep='\\t')\n",
    "#rename docid column to docno\n",
    "docno_to_text = docno_to_text.rename(columns={'docid':'docno'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_from_docno(docno):\n",
    "    print(docno)\n",
    "    if docno_to_text[docno_to_text['docno'] == docno].empty:\n",
    "        return ''\n",
    "    return docno_to_text[docno_to_text['docno'] == docno]['text'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "\n",
    "def load_topics(path, clean_queries=False):\n",
    "    with open(path) as f:\n",
    "        root = ET.fromstring(f.read())\n",
    "    topic_dict = {}\n",
    "    for topic in root.findall(\"topic\"):\n",
    "        topic_id = topic.findtext(\"id\")\n",
    "        topic_query = topic.findtext(\"query\")\n",
    "        if topic_id and topic_query:\n",
    "            topic_dict[topic_id] = topic_query.strip()\n",
    "    topics = pd.DataFrame(topic_dict.items(), columns=[\"qid\", \"query\"]) \n",
    "    if clean_queries:\n",
    "        topics[\"query\"] = topics[\"query\"].str.lower().replace(r'\\W+', ' ', regex=True)\n",
    "    return topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = load_topics(\"../data/topics/topics.txt\", clean_queries=True)\n",
    "qrels = pt.io.read_qrels(\"../data/assessments/qrels.txt\") # type: ignore\n",
    "qcred = pt.io.read_qrels(\"../data/assessments/qcredibility.txt\") # type: ignore\n",
    "qread = pt.io.read_qrels(\"../data/assessments/qreadability.txt\") # type: ignore\n",
    "\n",
    "all_qs = [(\"qrels\", qrels), (\"qcred\", qcred), (\"qread\", qread)]\n",
    "\n",
    "# remove non alphanumeric characters from queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add qid to docno_to_text based on join with qrels . If multiple qids, add all of them\n",
    "docno_to_text['qid'] = docno_to_text['docno'].apply(lambda x: qrels[qrels['docno'] == x]['qid'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_llms = ['', 'chatgpt_clean_queries', 'falcon7b_prompt', 'falcon40b_prompt', 'OA_LLama']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?queries/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jonas/miniconda3/envs/faiss/lib/python3.8/site-packages/scipy/__init__.py:143: UserWarning: A NumPy version >=1.19.5 and <1.27.0 is required for this version of SciPy (detected version 1.19.2)\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "100%|██████████| 50/50 [00:30<00:00,  1.64queries/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>judgement</th>\n",
       "      <th>qid</th>\n",
       "      <th>query</th>\n",
       "      <th>ndcg@10</th>\n",
       "      <th>map</th>\n",
       "      <th>bpref</th>\n",
       "      <th>name</th>\n",
       "      <th>num_docs</th>\n",
       "      <th>num_results</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>qrels</td>\n",
       "      <td>1</td>\n",
       "      <td>what are the most common chronic diseases what effects do chronic diseases have for the society ...</td>\n",
       "      <td>0.895853</td>\n",
       "      <td>0.735476</td>\n",
       "      <td>0.539382</td>\n",
       "      <td>QE_dph_over_50_base</td>\n",
       "      <td>244</td>\n",
       "      <td>244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>qcred</td>\n",
       "      <td>1</td>\n",
       "      <td>what are the most common chronic diseases what effects do chronic diseases have for the society ...</td>\n",
       "      <td>0.764162</td>\n",
       "      <td>0.764478</td>\n",
       "      <td>0.506195</td>\n",
       "      <td>QE_dph_over_50_base</td>\n",
       "      <td>244</td>\n",
       "      <td>244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>qread</td>\n",
       "      <td>1</td>\n",
       "      <td>what are the most common chronic diseases what effects do chronic diseases have for the society ...</td>\n",
       "      <td>0.963318</td>\n",
       "      <td>0.959591</td>\n",
       "      <td>0.689566</td>\n",
       "      <td>QE_dph_over_50_base</td>\n",
       "      <td>244</td>\n",
       "      <td>244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>qrels</td>\n",
       "      <td>8</td>\n",
       "      <td>best apps daily activity exercise diabetes</td>\n",
       "      <td>0.347912</td>\n",
       "      <td>0.204938</td>\n",
       "      <td>0.176860</td>\n",
       "      <td>QE_dph_over_50_base</td>\n",
       "      <td>235</td>\n",
       "      <td>233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>qcred</td>\n",
       "      <td>8</td>\n",
       "      <td>best apps daily activity exercise diabetes</td>\n",
       "      <td>0.502905</td>\n",
       "      <td>0.895949</td>\n",
       "      <td>0.678797</td>\n",
       "      <td>QE_dph_over_50_base</td>\n",
       "      <td>235</td>\n",
       "      <td>233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>qcred</td>\n",
       "      <td>131</td>\n",
       "      <td>exercises for better posture</td>\n",
       "      <td>0.576404</td>\n",
       "      <td>0.501183</td>\n",
       "      <td>0.511529</td>\n",
       "      <td>QE_dph_over_50_base</td>\n",
       "      <td>84</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>qread</td>\n",
       "      <td>131</td>\n",
       "      <td>exercises for better posture</td>\n",
       "      <td>0.836347</td>\n",
       "      <td>0.318078</td>\n",
       "      <td>0.280833</td>\n",
       "      <td>QE_dph_over_50_base</td>\n",
       "      <td>84</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>qrels</td>\n",
       "      <td>132</td>\n",
       "      <td>headpats scalp psoriasis</td>\n",
       "      <td>0.726305</td>\n",
       "      <td>0.454830</td>\n",
       "      <td>0.520657</td>\n",
       "      <td>QE_dph_over_50_base</td>\n",
       "      <td>124</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>qcred</td>\n",
       "      <td>132</td>\n",
       "      <td>headpats scalp psoriasis</td>\n",
       "      <td>0.714093</td>\n",
       "      <td>0.774452</td>\n",
       "      <td>0.796364</td>\n",
       "      <td>QE_dph_over_50_base</td>\n",
       "      <td>124</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>qread</td>\n",
       "      <td>132</td>\n",
       "      <td>headpats scalp psoriasis</td>\n",
       "      <td>0.892491</td>\n",
       "      <td>0.543414</td>\n",
       "      <td>0.562843</td>\n",
       "      <td>QE_dph_over_50_base</td>\n",
       "      <td>124</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    judgement  qid  \\\n",
       "0       qrels    1   \n",
       "1       qcred    1   \n",
       "2       qread    1   \n",
       "3       qrels    8   \n",
       "4       qcred    8   \n",
       "..        ...  ...   \n",
       "145     qcred  131   \n",
       "146     qread  131   \n",
       "147     qrels  132   \n",
       "148     qcred  132   \n",
       "149     qread  132   \n",
       "\n",
       "                                                                                                   query  \\\n",
       "0    what are the most common chronic diseases what effects do chronic diseases have for the society ...   \n",
       "1    what are the most common chronic diseases what effects do chronic diseases have for the society ...   \n",
       "2    what are the most common chronic diseases what effects do chronic diseases have for the society ...   \n",
       "3                                                             best apps daily activity exercise diabetes   \n",
       "4                                                             best apps daily activity exercise diabetes   \n",
       "..                                                                                                   ...   \n",
       "145                                                                         exercises for better posture   \n",
       "146                                                                         exercises for better posture   \n",
       "147                                                                             headpats scalp psoriasis   \n",
       "148                                                                             headpats scalp psoriasis   \n",
       "149                                                                             headpats scalp psoriasis   \n",
       "\n",
       "      ndcg@10       map     bpref                 name num_docs num_results  \n",
       "0    0.895853  0.735476  0.539382  QE_dph_over_50_base      244         244  \n",
       "1    0.764162  0.764478  0.506195  QE_dph_over_50_base      244         244  \n",
       "2    0.963318  0.959591  0.689566  QE_dph_over_50_base      244         244  \n",
       "3    0.347912  0.204938  0.176860  QE_dph_over_50_base      235         233  \n",
       "4    0.502905  0.895949  0.678797  QE_dph_over_50_base      235         233  \n",
       "..        ...       ...       ...                  ...      ...         ...  \n",
       "145  0.576404  0.501183  0.511529  QE_dph_over_50_base       84          84  \n",
       "146  0.836347  0.318078  0.280833  QE_dph_over_50_base       84          84  \n",
       "147  0.726305  0.454830  0.520657  QE_dph_over_50_base      124         112  \n",
       "148  0.714093  0.774452  0.796364  QE_dph_over_50_base      124         112  \n",
       "149  0.892491  0.543414  0.562843  QE_dph_over_50_base      124         112  \n",
       "\n",
       "[150 rows x 9 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "use_colbert = True\n",
    "retrieval_results = pd.DataFrame(columns=['judgement', 'qid', 'query', 'ndcg@10', 'map', 'bpref', 'name', 'num_docs', 'num_results'])\n",
    "\n",
    "def yield_passages_from_df(df):\n",
    "    for index, row in df.iterrows():\n",
    "        yield {'docno': row['docno'], 'text': row['text']}\n",
    "\n",
    "\n",
    "for index, row in tqdm(topics.iterrows(), total=topics.shape[0], position=0, leave=True, unit='queries'):\n",
    "    qid = row['qid']\n",
    "    query = row['query']\n",
    "    # make copy of docno_to_text for all rows where qid is in qid\n",
    "    passages_for_query = docno_to_text[docno_to_text['qid'].apply(lambda x: qid in x)].copy()\n",
    "    num_docs = passages_for_query.shape[0]\n",
    "    # create index for this query\n",
    "    # delete index if it exists\n",
    "    index_path = \"./indexes/\" + 'base' + \"/query_\" + qid\n",
    "    if os.path.exists(index_path):\n",
    "        shutil.rmtree(index_path)\n",
    "    index = pt.DFIndexer(index_path)\n",
    "    index.index(passages_for_query['text'], passages_for_query['docno'])\n",
    "    dph = pt.BatchRetrieve(index, wmodel=\"DPH\")\n",
    "    # tfidf = pt.BatchRetrieve(indexref, wmodel=\"TF_IDF\", metadata=[\"docno\", \"text\"])\n",
    "    bo1 = pt.rewrite.Bo1QueryExpansion(index)\n",
    "    pipeline = dph >> bo1 >> dph # >> readability_rerank\n",
    "    simple_name = 'QE_dph_over_50_base'\n",
    "    \n",
    "    # run pipeline and calculate ndcg@10\n",
    "    res = pipeline.search(query)\n",
    "    res['qid'] = qid\n",
    "    num_results = res.shape[0]\n",
    "    judgements = {'qrels': qrels, 'qcred': qcred, 'qread': qread}\n",
    "    for name, q in judgements.items():\n",
    "        exp = pt.Experiment([res], topics[topics['qid'] == qid], q[q['qid'] == qid], eval_metrics=['ndcg_cut_10', 'map', 'bpref'], names=[simple_name])\n",
    "        ndcg = exp['ndcg_cut_10'][0]\n",
    "        result_df = pd.DataFrame({'judgement': name, 'qid': qid, 'query': query, 'ndcg@10': ndcg, 'map': exp['map'][0], 'bpref': exp['bpref'][0], 'name': simple_name, 'num_docs': num_docs, 'num_results': num_results}, index=[0])\n",
    "        retrieval_results = pd.concat([retrieval_results, result_df], ignore_index=True)\n",
    "   \n",
    "retrieval_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_48384/326055405.py:2: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  average_scores = retrieval_results.groupby(['judgement', 'name'])['ndcg@10', 'map', 'bpref'].mean()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>ndcg@10</th>\n",
       "      <th>map</th>\n",
       "      <th>bpref</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>judgement</th>\n",
       "      <th>name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>qrels</th>\n",
       "      <th>QE_dph_over_50_base</th>\n",
       "      <td>0.509754</td>\n",
       "      <td>0.469400</td>\n",
       "      <td>0.432712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qcred</th>\n",
       "      <th>QE_dph_over_50_base</th>\n",
       "      <td>0.637488</td>\n",
       "      <td>0.773065</td>\n",
       "      <td>0.729664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qread</th>\n",
       "      <th>QE_dph_over_50_base</th>\n",
       "      <td>0.751416</td>\n",
       "      <td>0.643351</td>\n",
       "      <td>0.465262</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                ndcg@10       map     bpref\n",
       "judgement name                                             \n",
       "qrels     QE_dph_over_50_base  0.509754  0.469400  0.432712\n",
       "qcred     QE_dph_over_50_base  0.637488  0.773065  0.729664\n",
       "qread     QE_dph_over_50_base  0.751416  0.643351  0.465262"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get average ndcg@10, map, bpref for each judgement\n",
    "average_scores = retrieval_results.groupby(['judgement', 'name'])['ndcg@10', 'map', 'bpref'].mean()\n",
    "# sort in order [qrels, qcred, qread]\n",
    "average_scores = average_scores.reindex(['qrels', 'qcred', 'qread'], level=0)\n",
    "average_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No answer file for \n",
      "Skipping...\n",
      "No answer file for chatgpt_clean_queries\n",
      "Skipping...\n",
      "No answer file for falcon7b_prompt\n",
      "Skipping...\n",
      "No answer file for falcon40b_prompt\n",
      "Skipping...\n",
      "No answer file for OA_LLama\n",
      "Skipping...\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "results = pd.DataFrame(columns=['qid', 'query', 'llm', 'docno', 'rank', 'score', 'run_name', 'total_results', 'total_num_docs'])\n",
    "for llm in all_llms:\n",
    "    try:\n",
    "        llm_answers = pd.read_csv('data/all_answers_' + llm + '.csv', header='infer', quotechar='\"', skipinitialspace=True)\n",
    "    except:\n",
    "        print('No answer file for ' + llm)\n",
    "        print('Skipping...')\n",
    "        continue\n",
    "    llm_answers['qid'] = llm_answers['qid'].astype(str)\n",
    "    for index, row in tqdm(topics.iterrows(), total=topics.shape[0], desc=llm, position=0, leave=True, unit='queries'):\n",
    "        qid = row['qid']\n",
    "        if qid not in llm_answers['qid'].values:\n",
    "           continue\n",
    "        # get result rows for this qid\n",
    "        qid_results = llm_answers[llm_answers['qid'] == qid]\n",
    "        #add qid_results to docno_to_text\n",
    "        docid = llm + '_' + qid\n",
    "        # make copy of docno_to_text for all rows where qid is in qid\n",
    "        passages_for_query = docno_to_text[docno_to_text['qid'].apply(lambda x: qid in x)].copy()\n",
    "        # add new row\n",
    "        new_row ={'docno': docid, 'text': qid_results['answer'], 'qid': [[qid]]} \n",
    "        passages_for_query = pd.concat([passages_for_query, pd.DataFrame(new_row)])\n",
    "        \n",
    "        # create index for this query\n",
    "        # delete index if it exists\n",
    "        if os.path.exists(\"./data/indexes/\" + llm + \"/query_\" + qid):\n",
    "            shutil.rmtree(\"./data/indexes/\" + llm + \"/query_\" + qid)\n",
    "        index = pt.DFIndexer(\"./data/indexes/\" + llm + \"/query_\" + qid)\n",
    "        index.index(passages_for_query['text'], passages_for_query['docno'])\n",
    "\n",
    "        dph = pt.BatchRetrieve(index, wmodel=\"DPH\")\n",
    "        # tfidf = pt.BatchRetrieve(indexref, wmodel=\"TF_IDF\", metadata=[\"docno\", \"text\"])\n",
    "        bo1 = pt.rewrite.Bo1QueryExpansion(index)\n",
    "        pipelineQE_dph = dph >> bo1 >> dph # >> readability_rerank\n",
    "        simple_name = 'QE_dph_over_50_' + llm\n",
    "        \n",
    "        # run pipeline\n",
    "        res = pipelineQE_dph.search(row['query'])\n",
    "        total_results = len(res['docno'].tolist())\n",
    "        total_num_docs = passages_for_query.shape[0] - 1\n",
    "        \n",
    "        # get rank of docid\n",
    "        if docid not in res['docno'].tolist():\n",
    "            rank = total_results + 1\n",
    "            score = 0\n",
    "        else:\n",
    "            rank = res['docno'].tolist().index(docid) + 1\n",
    "            # get score of docid\n",
    "            score = res['score'].tolist()[rank - 1]\n",
    "        # add row to results\n",
    "        results = pd.concat([results, pd.DataFrame({'qid': [qid], 'query': [row['query']], 'llm': [llm], 'docno': [docid], 'rank': [rank], 'score': [score], 'run_name': [simple_name], 'total_results': [total_results], 'total_num_docs': [total_num_docs]})])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "average rank: nan\n",
      "number of 1s: 0\n",
      "\n",
      "chatgpt_clean_queries\n",
      "average rank: nan\n",
      "number of 1s: 0\n",
      "\n",
      "falcon7b_prompt\n",
      "average rank: nan\n",
      "number of 1s: 0\n",
      "\n",
      "falcon40b_prompt\n",
      "average rank: nan\n",
      "number of 1s: 0\n",
      "\n",
      "OA_LLama\n",
      "average rank: nan\n",
      "number of 1s: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# for each llm, get average rank and total amount of number 1s\n",
    "for llm in all_llms:\n",
    "    print(llm)\n",
    "    llm_res = results[results['llm'] == llm]\n",
    "    average_rank = llm_res['rank'].mean()\n",
    "    print('average rank: ' + str(average_rank))\n",
    "    num_1s = llm_res[llm_res['rank'] == 1].shape[0]\n",
    "    print('number of 1s: ' + str(num_1s))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>query</th>\n",
       "      <th>llm</th>\n",
       "      <th>docno</th>\n",
       "      <th>rank</th>\n",
       "      <th>score</th>\n",
       "      <th>run_name</th>\n",
       "      <th>total_results</th>\n",
       "      <th>total_num_docs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [qid, query, llm, docno, rank, score, run_name, total_results, total_num_docs]\n",
       "Index: []"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyterrier as pt\n",
    "\n",
    "def run_experiment(pipeline, simple_name, topics, qrels, eval_metrics=[\"map\", \"bpref\", \"ndcg_cut_10\"]):\n",
    "    experiments = []\n",
    "    for name, q in qrels:\n",
    "        # change pipeline name to include the name of the query\n",
    "\n",
    "        exp = pt.Experiment([pipeline], topics, q, eval_metrics, names=[name + '_' + simple_name])\n",
    "        experiments.append(exp)\n",
    "    return pd.concat(experiments, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/all_passages_credibility_scores_bert.tsv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m credibility_scores \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m'\u001b[39;49m\u001b[39mdata/all_passages_credibility_scores_bert.tsv\u001b[39;49m\u001b[39m'\u001b[39;49m, sep\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m\\t\u001b[39;49;00m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m~/miniconda3/envs/faiss/lib/python3.8/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[39m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/faiss/lib/python3.8/site-packages/pandas/io/parsers/readers.py:678\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    663\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    664\u001b[0m     dialect,\n\u001b[1;32m    665\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    674\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[1;32m    675\u001b[0m )\n\u001b[1;32m    676\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 678\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/miniconda3/envs/faiss/lib/python3.8/site-packages/pandas/io/parsers/readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    572\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    574\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 575\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    577\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[1;32m    578\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/miniconda3/envs/faiss/lib/python3.8/site-packages/pandas/io/parsers/readers.py:932\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    929\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    931\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 932\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[0;32m~/miniconda3/envs/faiss/lib/python3.8/site-packages/pandas/io/parsers/readers.py:1216\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1212\u001b[0m     mode \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1213\u001b[0m \u001b[39m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[1;32m   1214\u001b[0m \u001b[39m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[1;32m   1215\u001b[0m \u001b[39m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[0;32m-> 1216\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(  \u001b[39m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[1;32m   1217\u001b[0m     f,\n\u001b[1;32m   1218\u001b[0m     mode,\n\u001b[1;32m   1219\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1220\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1221\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[1;32m   1222\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[1;32m   1223\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1224\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1225\u001b[0m )\n\u001b[1;32m   1226\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1227\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/miniconda3/envs/faiss/lib/python3.8/site-packages/pandas/io/common.py:786\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    781\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    782\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    783\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    784\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[1;32m    785\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[0;32m--> 786\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[1;32m    787\u001b[0m             handle,\n\u001b[1;32m    788\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[1;32m    789\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[1;32m    790\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m    791\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    792\u001b[0m         )\n\u001b[1;32m    793\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    794\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[1;32m    795\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/all_passages_credibility_scores_bert.tsv'"
     ]
    }
   ],
   "source": [
    "credibility_scores = pd.read_csv('data/all_passages_credibility_scores_bert.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the credibility score for a given docid\n",
    "def get_credibility_score(docid):\n",
    "    if credibility_scores[credibility_scores['docid'] == docid].empty:\n",
    "        return 0\n",
    "    return credibility_scores[credibility_scores['docid'] == docid]['credibility_score'].values[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textstat\n",
    "# rank documents with custom function that evaluates readability of the document\n",
    "def readability_score(text):\n",
    "    score = textstat.flesch_reading_ease(text)\n",
    "    print(score)\n",
    "    return score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jonas/miniconda3/envs/faiss/lib/python3.8/site-packages/scipy/__init__.py:143: UserWarning: A NumPy version >=1.19.5 and <1.27.0 is required for this version of SciPy (detected version 1.19.2)\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m simple_name \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mQE_dph_over_50_\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m identifier\n\u001b[1;32m     15\u001b[0m retrieval \u001b[39m=\u001b[39m pipelineQE_dph\n\u001b[0;32m---> 16\u001b[0m results \u001b[39m=\u001b[39m run_experiment(retrieval, simple_name, topics, all_qs, [\u001b[39m\"\u001b[39;49m\u001b[39mmap\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mbpref\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mndcg_cut_10\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n\u001b[1;32m     17\u001b[0m all_results\u001b[39m.\u001b[39mappend({\u001b[39m'\u001b[39m\u001b[39midentifier\u001b[39m\u001b[39m'\u001b[39m: identifier, \u001b[39m'\u001b[39m\u001b[39mresults\u001b[39m\u001b[39m'\u001b[39m: results, \u001b[39m'\u001b[39m\u001b[39mretrieval\u001b[39m\u001b[39m'\u001b[39m: retrieval})\n",
      "Cell \u001b[0;32mIn[11], line 8\u001b[0m, in \u001b[0;36mrun_experiment\u001b[0;34m(pipeline, simple_name, topics, qrels, eval_metrics)\u001b[0m\n\u001b[1;32m      4\u001b[0m experiments \u001b[39m=\u001b[39m []\n\u001b[1;32m      5\u001b[0m \u001b[39mfor\u001b[39;00m name, q \u001b[39min\u001b[39;00m qrels:\n\u001b[1;32m      6\u001b[0m     \u001b[39m# change pipeline name to include the name of the query\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m     exp \u001b[39m=\u001b[39m pt\u001b[39m.\u001b[39;49mExperiment([pipeline], topics, q, eval_metrics, names\u001b[39m=\u001b[39;49m[name \u001b[39m+\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39m_\u001b[39;49m\u001b[39m'\u001b[39;49m \u001b[39m+\u001b[39;49m simple_name])\n\u001b[1;32m      9\u001b[0m     experiments\u001b[39m.\u001b[39mappend(exp)\n\u001b[1;32m     10\u001b[0m \u001b[39mreturn\u001b[39;00m pd\u001b[39m.\u001b[39mconcat(experiments, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/faiss/lib/python3.8/site-packages/pyterrier/pipelines.py:450\u001b[0m, in \u001b[0;36mExperiment\u001b[0;34m(retr_systems, topics, qrels, eval_metrics, names, perquery, dataframe, batch_size, filter_by_qrels, filter_by_topics, baseline, test, correction, correction_alpha, highlight, round, verbose, save_dir, save_mode, **kwargs)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[39mif\u001b[39;00m save_dir \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    448\u001b[0m     save_file \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(save_dir, \u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m.res.gz\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m name)\n\u001b[0;32m--> 450\u001b[0m time, evalMeasuresDict \u001b[39m=\u001b[39m _run_and_evaluate(\n\u001b[1;32m    451\u001b[0m     system, topics, qrels, eval_metrics, \n\u001b[1;32m    452\u001b[0m     perquery\u001b[39m=\u001b[39;49mperquery \u001b[39mor\u001b[39;49;00m baseline \u001b[39mis\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m, \n\u001b[1;32m    453\u001b[0m     batch_size\u001b[39m=\u001b[39;49mbatch_size, \n\u001b[1;32m    454\u001b[0m     backfill_qids\u001b[39m=\u001b[39;49mall_topic_qids \u001b[39mif\u001b[39;49;00m perquery \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    455\u001b[0m     save_file\u001b[39m=\u001b[39;49msave_file,\n\u001b[1;32m    456\u001b[0m     save_mode\u001b[39m=\u001b[39;49msave_mode,\n\u001b[1;32m    457\u001b[0m     pbar\u001b[39m=\u001b[39;49mpbar)\n\u001b[1;32m    459\u001b[0m \u001b[39mif\u001b[39;00m baseline \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    460\u001b[0m     evalDictsPerQ\u001b[39m.\u001b[39mappend(evalMeasuresDict)\n",
      "File \u001b[0;32m~/miniconda3/envs/faiss/lib/python3.8/site-packages/pyterrier/pipelines.py:170\u001b[0m, in \u001b[0;36m_run_and_evaluate\u001b[0;34m(system, topics, qrels, metrics, pbar, save_mode, save_file, perquery, batch_size, backfill_qids)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[39melif\u001b[39;00m batch_size \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    167\u001b[0m     \u001b[39m#transformer, evaluate all queries at once\u001b[39;00m\n\u001b[1;32m    169\u001b[0m     starttime \u001b[39m=\u001b[39m timer()\n\u001b[0;32m--> 170\u001b[0m     res \u001b[39m=\u001b[39m system\u001b[39m.\u001b[39;49mtransform(topics)\n\u001b[1;32m    171\u001b[0m     endtime \u001b[39m=\u001b[39m timer()\n\u001b[1;32m    172\u001b[0m     runtime \u001b[39m=\u001b[39m  (endtime \u001b[39m-\u001b[39m starttime) \u001b[39m*\u001b[39m \u001b[39m1000.\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/faiss/lib/python3.8/site-packages/pyterrier/ops.py:335\u001b[0m, in \u001b[0;36mComposedPipeline.transform\u001b[0;34m(self, topics)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtransform\u001b[39m(\u001b[39mself\u001b[39m, topics):\n\u001b[1;32m    334\u001b[0m     \u001b[39mfor\u001b[39;00m m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodels:\n\u001b[0;32m--> 335\u001b[0m         topics \u001b[39m=\u001b[39m m\u001b[39m.\u001b[39;49mtransform(topics)\n\u001b[1;32m    336\u001b[0m     \u001b[39mreturn\u001b[39;00m topics\n",
      "File \u001b[0;32m~/miniconda3/envs/faiss/lib/python3.8/site-packages/pyterrier/batchretrieve.py:441\u001b[0m, in \u001b[0;36mBatchRetrieve.transform\u001b[0;34m(self, queries)\u001b[0m\n\u001b[1;32m    439\u001b[0m         \u001b[39miter\u001b[39m \u001b[39m=\u001b[39m tqdm(\u001b[39miter\u001b[39m, desc\u001b[39m=\u001b[39m\u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m), total\u001b[39m=\u001b[39mqueries\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], unit\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mq\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    440\u001b[0m     \u001b[39mfor\u001b[39;00m row \u001b[39min\u001b[39;00m \u001b[39miter\u001b[39m:\n\u001b[0;32m--> 441\u001b[0m         res \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_retrieve_one(row, input_results, docno_provided\u001b[39m=\u001b[39;49mdocno_provided, docid_provided\u001b[39m=\u001b[39;49mdocid_provided, scores_provided\u001b[39m=\u001b[39;49mscores_provided)\n\u001b[1;32m    442\u001b[0m         results\u001b[39m.\u001b[39mextend(res)\n\u001b[1;32m    444\u001b[0m res_dt \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(results, columns\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mqid\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mdocid\u001b[39m\u001b[39m'\u001b[39m ] \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmetadata \u001b[39m+\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mrank\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mscore\u001b[39m\u001b[39m'\u001b[39m])\n",
      "File \u001b[0;32m~/miniconda3/envs/faiss/lib/python3.8/site-packages/pyterrier/batchretrieve.py:352\u001b[0m, in \u001b[0;36mBatchRetrieve._retrieve_one\u001b[0;34m(self, row, input_results, docno_provided, docid_provided, scores_provided)\u001b[0m\n\u001b[1;32m    349\u001b[0m     srq\u001b[39m.\u001b[39msetControl(\u001b[39m\"\u001b[39m\u001b[39mmatching\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39morg.terrier.matching.ScoringMatching\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m srq\u001b[39m.\u001b[39mgetControl(\u001b[39m\"\u001b[39m\u001b[39mmatching\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[1;32m    351\u001b[0m \u001b[39m# now ask Terrier to run the request\u001b[39;00m\n\u001b[0;32m--> 352\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmanager\u001b[39m.\u001b[39;49mrunSearchRequest(srq)\n\u001b[1;32m    353\u001b[0m result \u001b[39m=\u001b[39m srq\u001b[39m.\u001b[39mgetResults()\n\u001b[1;32m    355\u001b[0m \u001b[39m# check we got all of the expected metadata (if the resultset has a size at all)\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "all_results = []\n",
    "if use_colbert:\n",
    "    retrieval = dense_e2e\n",
    "    simple_name = 'colbert_msmarco_over_50'\n",
    "else:\n",
    "    for indexref in indexrefs:\n",
    "        identifier = indexref['identifier']\n",
    "        indexref = indexref['indexref']\n",
    "        dph = pt.BatchRetrieve(indexref, wmodel=\"DPH\", metadata=[\"docno\", \"text\"])\n",
    "        # tfidf = pt.BatchRetrieve(indexref, wmodel=\"TF_IDF\", metadata=[\"docno\", \"text\"])\n",
    "        bo1 = pt.rewrite.Bo1QueryExpansion(indexref)\n",
    "        # readability_rerank = pt.apply.doc_score(lambda row: get_credibility_score(row['docid']))\n",
    "        pipelineQE_dph = dph >> bo1 >> dph # >> readability_rerank\n",
    "        simple_name = 'QE_dph_over_50_' + identifier\n",
    "        retrieval = pipelineQE_dph\n",
    "        llm_answers = run_experiment(retrieval, simple_name, topics, all_qs, [\"map\", \"bpref\", \"ndcg_cut_10\"])\n",
    "        all_results.append({'identifier': identifier, 'results': llm_answers, 'retrieval': retrieval})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'use_chatgpt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m append_to_file \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m----> 2\u001b[0m \u001b[39mif\u001b[39;00m use_chatgpt:\n\u001b[1;32m      3\u001b[0m     append_to_file \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m_chatgpt\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'use_chatgpt' is not defined"
     ]
    }
   ],
   "source": [
    "append_to_file = ''\n",
    "if use_chatgpt:\n",
    "    append_to_file = '_chatgpt'\n",
    "else:\n",
    "    append_to_file = '_without_chatgpt'\n",
    "\n",
    "llm_answers.to_csv('data/results/results_' + simple_name + append_to_file + '_clean_queries.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>map</th>\n",
       "      <th>bpref</th>\n",
       "      <th>ndcg_cut_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>qrels_QE_tfidf_over_50_IterDict</td>\n",
       "      <td>0.357313</td>\n",
       "      <td>0.447128</td>\n",
       "      <td>0.569338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>qcred_QE_tfidf_over_50_IterDict</td>\n",
       "      <td>0.505827</td>\n",
       "      <td>0.679313</td>\n",
       "      <td>0.623856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>qread_QE_tfidf_over_50_IterDict</td>\n",
       "      <td>0.403736</td>\n",
       "      <td>0.452294</td>\n",
       "      <td>0.722833</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              name       map     bpref  ndcg_cut_10\n",
       "0  qrels_QE_tfidf_over_50_IterDict  0.357313  0.447128     0.569338\n",
       "0  qcred_QE_tfidf_over_50_IterDict  0.505827  0.679313     0.623856\n",
       "0  qread_QE_tfidf_over_50_IterDict  0.403736  0.452294     0.722833"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_results[0]['results']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chatgpt_clean_queries1\n",
      "chatgpt_clean_queries8\n",
      "381d63ae-ec5f-4fa0-b331-7df8b0f63e38\n",
      "05d7038c-0ea2-41f7-b439-f1a80b6ae343\n",
      "1cc2d142-9499-4770-82ae-816108994dd9\n",
      "5c615aac-2089-4755-85cc-e43cd6d25f3f\n",
      "ac64710f-5be6-4338-81bf-f449341dbfc7\n",
      "c7087ca7-07b1-4a83-8b4f-750f42e2b248\n",
      "401363ff-141a-4cc9-8b47-484a277e102f\n",
      "94227313-076b-46c2-8aa9-ace1c7a6c19f\n",
      "30c124f4-0535-41d8-8afe-54d8b8ab9c54\n",
      "812e0336-7233-4286-908e-fd00e35724f5\n",
      "ac5e10e1-2da7-41a9-94a7-098461398997\n",
      "chatgpt_clean_queries62\n",
      "a1b0e7c2-2b4d-4430-9a08-a0e2a5ae99ba\n",
      "8c07ded1-c889-4259-ae03-c7d5a9817183\n",
      "cb5586bc-6eed-4739-be79-c232a507c20f\n",
      "chatgpt_clean_queries77\n",
      "ae5f0ad2-193c-491a-a61d-d058b7934607\n",
      "0378a4b6-930f-45d5-b518-ca90d8c2384f\n",
      "chatgpt_clean_queries83\n",
      "6b9c9f03-cb37-4e0f-9ac1-35b14551f750\n",
      "5e829a57-b1e6-4d23-aa53-db5834c8af30\n",
      "a9f343d9-958d-4d58-a76b-6a42b8442e7e\n",
      "chatgpt_clean_queries93\n",
      "92a08e89-6397-4ed4-a708-2ea1ce5e94fe\n",
      "cc99940b-32b0-4364-a184-7b80bbf6ee7c\n",
      "chatgpt_clean_queries96\n",
      "f9d4fc76-1b16-4c31-b707-d25ec46d977d\n",
      "57f56d68-7e40-4e3c-97f3-8e9718af5261\n",
      "c7eec525-ced7-476e-9e06-78a5d864e95f\n",
      "8a1e3317-a857-4e18-988a-2fd8f448d892\n",
      "5230ffc7-5376-4d70-a262-2624e11f01eb\n",
      "8b065d2e-0f78-4175-bb3a-bf05b56a68c1\n",
      "chatgpt_clean_queries108\n",
      "afa9ab3f-d1fe-40e9-81dd-66756c98d22d\n",
      "7d2e12ab-d7dd-4c85-9d08-15fe55e0dc31\n",
      "7a325d7e-cf32-43b8-a408-fca52b876da9\n",
      "a0913504-13dc-48a2-9b3a-d63cef161910\n",
      "ff1ad3f1-a1cd-4289-8bc4-03a910fb4fdf\n",
      "96a39c21-3114-4a14-9159-f800d423dc72\n",
      "f65e2dc7-7df5-4aa0-ac98-73d0b80af165\n",
      "64a8936c-d285-485f-a5de-5741d207887c\n",
      "f9776e76-373a-49bb-a4ec-0126f0a4c171\n",
      "3f3d11a7-18d6-4184-b53f-3d0b8ed44833\n",
      "chatgpt_clean_queries126\n",
      "9e3afb23-ffe2-4b40-b571-7f892c05af82\n",
      "3406c3cc-a32f-420d-a1d4-40b8e84d8b69\n",
      "259a8348-f2a4-4dad-baf9-415b846f394d\n",
      "80ad11ce-682c-40aa-8558-2815f59fbb55\n",
      "falcon7b_prompt1\n",
      "ca6dfa96-6c8b-4971-b8e3-969eca0ab7af\n",
      "381d63ae-ec5f-4fa0-b331-7df8b0f63e38\n",
      "05d7038c-0ea2-41f7-b439-f1a80b6ae343\n",
      "1cc2d142-9499-4770-82ae-816108994dd9\n",
      "5c615aac-2089-4755-85cc-e43cd6d25f3f\n",
      "ac64710f-5be6-4338-81bf-f449341dbfc7\n",
      "c7087ca7-07b1-4a83-8b4f-750f42e2b248\n",
      "falcon7b_prompt55\n",
      "falcon7b_prompt55\n",
      "30c124f4-0535-41d8-8afe-54d8b8ab9c54\n",
      "812e0336-7233-4286-908e-fd00e35724f5\n",
      "c4e90142-7bda-47dc-9368-7ae9aceeabb8\n",
      "172bac30-9e3b-4a70-9313-424f71e30546\n",
      "a1b0e7c2-2b4d-4430-9a08-a0e2a5ae99ba\n",
      "8c07ded1-c889-4259-ae03-c7d5a9817183\n",
      "c7b509b9-7ba1-4d8e-bf95-4e11625bb764\n",
      "falcon7b_prompt77\n",
      "ae5f0ad2-193c-491a-a61d-d058b7934607\n",
      "0378a4b6-930f-45d5-b518-ca90d8c2384f\n",
      "92a08e89-6397-4ed4-a708-2ea1ce5e94fe\n",
      "falcon7b_prompt85\n",
      "5e829a57-b1e6-4d23-aa53-db5834c8af30\n",
      "a9f343d9-958d-4d58-a76b-6a42b8442e7e\n",
      "e6db2935-c269-4b7d-b5b3-24bb99dd4942\n",
      "92a08e89-6397-4ed4-a708-2ea1ce5e94fe\n",
      "cc99940b-32b0-4364-a184-7b80bbf6ee7c\n",
      "ccf3beab-0bff-4dad-a751-8ef2016f95ae\n",
      "f9d4fc76-1b16-4c31-b707-d25ec46d977d\n",
      "57f56d68-7e40-4e3c-97f3-8e9718af5261\n",
      "bd5ee806-93d5-4fcf-89da-5235a2abad55\n",
      "8a1e3317-a857-4e18-988a-2fd8f448d892\n",
      "5230ffc7-5376-4d70-a262-2624e11f01eb\n",
      "8b065d2e-0f78-4175-bb3a-bf05b56a68c1\n",
      "falcon7b_prompt108\n",
      "afa9ab3f-d1fe-40e9-81dd-66756c98d22d\n",
      "7d2e12ab-d7dd-4c85-9d08-15fe55e0dc31\n",
      "7a325d7e-cf32-43b8-a408-fca52b876da9\n",
      "a0913504-13dc-48a2-9b3a-d63cef161910\n",
      "ff1ad3f1-a1cd-4289-8bc4-03a910fb4fdf\n",
      "96a39c21-3114-4a14-9159-f800d423dc72\n",
      "f65e2dc7-7df5-4aa0-ac98-73d0b80af165\n",
      "64a8936c-d285-485f-a5de-5741d207887c\n",
      "f9776e76-373a-49bb-a4ec-0126f0a4c171\n",
      "3f3d11a7-18d6-4184-b53f-3d0b8ed44833\n",
      "3e799e88-b8af-47f9-86c0-f712ed4acb9c\n",
      "9e3afb23-ffe2-4b40-b571-7f892c05af82\n",
      "3406c3cc-a32f-420d-a1d4-40b8e84d8b69\n",
      "259a8348-f2a4-4dad-baf9-415b846f394d\n",
      "falcon7b_prompt132\n",
      "falcon40b_prompt1\n",
      "ca6dfa96-6c8b-4971-b8e3-969eca0ab7af\n",
      "381d63ae-ec5f-4fa0-b331-7df8b0f63e38\n",
      "05d7038c-0ea2-41f7-b439-f1a80b6ae343\n",
      "1cc2d142-9499-4770-82ae-816108994dd9\n",
      "5c615aac-2089-4755-85cc-e43cd6d25f3f\n",
      "ac64710f-5be6-4338-81bf-f449341dbfc7\n",
      "c7087ca7-07b1-4a83-8b4f-750f42e2b248\n",
      "c4c613bd-599f-4573-b860-c10000857230\n",
      "94227313-076b-46c2-8aa9-ace1c7a6c19f\n",
      "30c124f4-0535-41d8-8afe-54d8b8ab9c54\n",
      "812e0336-7233-4286-908e-fd00e35724f5\n",
      "c4e90142-7bda-47dc-9368-7ae9aceeabb8\n",
      "9a17077a-7560-4787-8e30-7e12059e153b\n",
      "a1b0e7c2-2b4d-4430-9a08-a0e2a5ae99ba\n",
      "8c07ded1-c889-4259-ae03-c7d5a9817183\n",
      "c7b509b9-7ba1-4d8e-bf95-4e11625bb764\n",
      "0d760bbd-0e25-485f-a968-b494c7049224\n",
      "ae5f0ad2-193c-491a-a61d-d058b7934607\n",
      "0378a4b6-930f-45d5-b518-ca90d8c2384f\n",
      "92a08e89-6397-4ed4-a708-2ea1ce5e94fe\n",
      "6b9c9f03-cb37-4e0f-9ac1-35b14551f750\n",
      "5e829a57-b1e6-4d23-aa53-db5834c8af30\n",
      "a9f343d9-958d-4d58-a76b-6a42b8442e7e\n",
      "e6db2935-c269-4b7d-b5b3-24bb99dd4942\n",
      "92a08e89-6397-4ed4-a708-2ea1ce5e94fe\n",
      "cc99940b-32b0-4364-a184-7b80bbf6ee7c\n",
      "17772c53-9c8c-4c46-acf6-819c7daf427b\n",
      "f9d4fc76-1b16-4c31-b707-d25ec46d977d\n",
      "57f56d68-7e40-4e3c-97f3-8e9718af5261\n",
      "falcon40b_prompt101\n",
      "8a1e3317-a857-4e18-988a-2fd8f448d892\n",
      "5230ffc7-5376-4d70-a262-2624e11f01eb\n",
      "8b065d2e-0f78-4175-bb3a-bf05b56a68c1\n",
      "falcon40b_prompt108\n",
      "afa9ab3f-d1fe-40e9-81dd-66756c98d22d\n",
      "7d2e12ab-d7dd-4c85-9d08-15fe55e0dc31\n",
      "7a325d7e-cf32-43b8-a408-fca52b876da9\n",
      "a0913504-13dc-48a2-9b3a-d63cef161910\n",
      "ff1ad3f1-a1cd-4289-8bc4-03a910fb4fdf\n",
      "96a39c21-3114-4a14-9159-f800d423dc72\n",
      "f65e2dc7-7df5-4aa0-ac98-73d0b80af165\n",
      "64a8936c-d285-485f-a5de-5741d207887c\n",
      "f9776e76-373a-49bb-a4ec-0126f0a4c171\n",
      "3f3d11a7-18d6-4184-b53f-3d0b8ed44833\n",
      "3e799e88-b8af-47f9-86c0-f712ed4acb9c\n",
      "9e3afb23-ffe2-4b40-b571-7f892c05af82\n",
      "3406c3cc-a32f-420d-a1d4-40b8e84d8b69\n",
      "259a8348-f2a4-4dad-baf9-415b846f394d\n",
      "falcon40b_prompt132\n",
      "OA_LLama1\n",
      "ca6dfa96-6c8b-4971-b8e3-969eca0ab7af\n",
      "381d63ae-ec5f-4fa0-b331-7df8b0f63e38\n",
      "05d7038c-0ea2-41f7-b439-f1a80b6ae343\n",
      "1cc2d142-9499-4770-82ae-816108994dd9\n",
      "5c615aac-2089-4755-85cc-e43cd6d25f3f\n",
      "ac64710f-5be6-4338-81bf-f449341dbfc7\n",
      "c7087ca7-07b1-4a83-8b4f-750f42e2b248\n",
      "c4c613bd-599f-4573-b860-c10000857230\n",
      "94227313-076b-46c2-8aa9-ace1c7a6c19f\n",
      "30c124f4-0535-41d8-8afe-54d8b8ab9c54\n",
      "812e0336-7233-4286-908e-fd00e35724f5\n",
      "c4e90142-7bda-47dc-9368-7ae9aceeabb8\n",
      "172bac30-9e3b-4a70-9313-424f71e30546\n",
      "a1b0e7c2-2b4d-4430-9a08-a0e2a5ae99ba\n",
      "8c07ded1-c889-4259-ae03-c7d5a9817183\n",
      "c7b509b9-7ba1-4d8e-bf95-4e11625bb764\n",
      "0d760bbd-0e25-485f-a968-b494c7049224\n",
      "ae5f0ad2-193c-491a-a61d-d058b7934607\n",
      "0378a4b6-930f-45d5-b518-ca90d8c2384f\n",
      "92a08e89-6397-4ed4-a708-2ea1ce5e94fe\n",
      "6b9c9f03-cb37-4e0f-9ac1-35b14551f750\n",
      "5e829a57-b1e6-4d23-aa53-db5834c8af30\n",
      "a9f343d9-958d-4d58-a76b-6a42b8442e7e\n",
      "e6db2935-c269-4b7d-b5b3-24bb99dd4942\n",
      "4907cdae-f03f-40cf-9a94-8c78ac8e1c81\n",
      "cc99940b-32b0-4364-a184-7b80bbf6ee7c\n",
      "385f0cb8-a09e-4a18-ba55-fcacc2372bdd\n",
      "f9d4fc76-1b16-4c31-b707-d25ec46d977d\n",
      "57f56d68-7e40-4e3c-97f3-8e9718af5261\n",
      "c7eec525-ced7-476e-9e06-78a5d864e95f\n",
      "8a1e3317-a857-4e18-988a-2fd8f448d892\n",
      "5230ffc7-5376-4d70-a262-2624e11f01eb\n",
      "8b065d2e-0f78-4175-bb3a-bf05b56a68c1\n",
      "0a39858a-7cc0-488e-b848-d6188e9ad29a\n",
      "afa9ab3f-d1fe-40e9-81dd-66756c98d22d\n",
      "7d2e12ab-d7dd-4c85-9d08-15fe55e0dc31\n",
      "7a325d7e-cf32-43b8-a408-fca52b876da9\n",
      "a0913504-13dc-48a2-9b3a-d63cef161910\n",
      "ff1ad3f1-a1cd-4289-8bc4-03a910fb4fdf\n",
      "96a39c21-3114-4a14-9159-f800d423dc72\n",
      "f65e2dc7-7df5-4aa0-ac98-73d0b80af165\n",
      "64a8936c-d285-485f-a5de-5741d207887c\n",
      "4916784f-ccbc-40f7-a453-e7b2aad040bb\n",
      "3f3d11a7-18d6-4184-b53f-3d0b8ed44833\n",
      "3e799e88-b8af-47f9-86c0-f712ed4acb9c\n",
      "9e3afb23-ffe2-4b40-b571-7f892c05af82\n",
      "3406c3cc-a32f-420d-a1d4-40b8e84d8b69\n",
      "259a8348-f2a4-4dad-baf9-415b846f394d\n",
      "80ad11ce-682c-40aa-8558-2815f59fbb55\n"
     ]
    }
   ],
   "source": [
    "# iterate over topics and save the positions of chatgpt answers\n",
    "# if use_colbert:\n",
    "#     retrieval_model = dense_e2e\n",
    "# else:\n",
    "#     retrieval_model = pipelineQE_dph\n",
    "out_dfs = []\n",
    "for llm_number, result in enumerate(all_results[1:]):\n",
    "    identifier = result['identifier'].replace('IterDict_', '')\n",
    "    llm_answers = result['results']\n",
    "    retrieval_model = result['retrieval']\n",
    "    out_df = []\n",
    "    for idx, row in topics.iterrows():\n",
    "        res = retrieval_model.search(row[\"query\"])\n",
    "        best_answer_text = get_text_from_docno(res['docno'].tolist()[0])\n",
    "        llm_answer = all_llm_answers[llm_number]['results'][all_llm_answers[llm_number]['results']['topic_id'] == str(row['qid'])]['answer'].values[0]\n",
    "        docno = identifier + str(row['qid'])\n",
    "        if docno not in res['docno'].values:\n",
    "            out_df.append({'qid': row['qid'], 'query': row['query'], 'llm': identifier, 'docno': docno, 'position': -1, 'llm_answer': llm_answer[:2000], 'best_answer_if_not_llm': best_answer_text})\n",
    "            continue\n",
    "        position = res['docno'].tolist().index(docno)\n",
    "        out_df.append({'qid': row['qid'], 'query': row['query'], 'llm': identifier, 'docno': docno, 'position': position, 'llm_answer': llm_answer[:2000], 'best_answer_if_not_llm': best_answer_text})\n",
    "        \n",
    "    out_dfs.append(pd.DataFrame(out_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "for out_df in out_dfs:\n",
    "    date = datetime.now().strftime(\"%d%m%Y\")\n",
    "    identifier = out_df['docno'].tolist()[0][:-2]\n",
    "    if use_colbert:\n",
    "        out_file = f'data/{identifier}-{date}-positions-{simple_name}.csv'\n",
    "    else:\n",
    "        out_file = f'data/{identifier}-{date}-positions-{simple_name}.csv'\n",
    "    out_df.to_csv(out_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40.2\n",
      "0       1\n",
      "1       8\n",
      "13     62\n",
      "17     77\n",
      "20     83\n",
      "24     93\n",
      "27     96\n",
      "34    108\n",
      "45    126\n",
      "Name: qid, dtype: object\n",
      "54.66\n",
      "0       1\n",
      "9      55\n",
      "17     77\n",
      "21     85\n",
      "34    108\n",
      "49    132\n",
      "Name: qid, dtype: object\n",
      "112.92\n",
      "0       1\n",
      "30    101\n",
      "34    108\n",
      "49    132\n",
      "Name: qid, dtype: object\n",
      "144.54\n",
      "0    1\n",
      "Name: qid, dtype: object\n"
     ]
    }
   ],
   "source": [
    "for out_df in out_dfs:\n",
    "    print(out_df['position'].mean())\n",
    "    # print number 1 positions\n",
    "    print(out_df[out_df['position'] == 0]['qid'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "terrier",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
